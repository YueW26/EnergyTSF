user config:
seed 666
device 0
scaler StandardScaler()
day_slot 288
n_route 228
n_his 12
n_pred 12
n_train 34
n_val 5
n_test 5
mode 1
n_c 10
model STAGNN_stamp
TPG TPGNN
name PeMS
log_path log/TPGNN_r05p02kt3outer_115
crash 115
new_name TPGNN_r05p02kt3outer_115
batch_size 50
lr 0.001
a 0.1
r 0.5
n_mask 1
adam {'use': True, 'weight_decay': 0.0001}
slr {'use': True, 'step_size': 400, 'gamma': 0.3}
resume False
start_epoch 0
epochs 1500
n_layer 1
n_attr 64
n_hid 512
reg_A 0.0001
circle 288
drop_prob 0.2
CE {'use': True, 'kernel_size': 1, 'bias': False}
LE {'use': False, 'bias': False}
SE {'use': True, 'separate': True, 'no': False}
TE {'use': True, 'no': True}
attn {'head': 1, 'd_k': 32, 'd_v': 32, 'drop_prob': 0.2}
STstamp {'use': True, 'kt': 3, 'temperature': 1.0}
T4N {'use': True, 'step': 2, 'end_epoch': 10000, 'change_head': True, 'change_enc': True}
stamp_path data/PeMS/time_stamp.npy
data_path /home/kit/aifb/cc7738/scratch/EnergyTSF/datasets/France_processed_0.csv
adj_matrix_path /home/kit/aifb/cc7738/scratch/EnergyTSF/datasets/France_processed_0_adj_mx.pkl
dis_mat tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0.],
        [0., 0., 1., 1., 0., 1., 1., 1., 1., 0.],
        [1., 1., 0., 1., 0., 1., 1., 1., 1., 1.],
        [0., 1., 1., 0., 0., 1., 1., 0., 0., 0.],
        [0., 0., 0., 0., 0., 1., 1., 0., 0., 0.],
        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0.],
        [1., 1., 1., 1., 1., 1., 0., 1., 1., 0.],
        [0., 1., 1., 0., 0., 1., 1., 0., 1., 0.],
        [0., 1., 1., 0., 0., 0., 1., 1., 0., 1.],
        [0., 0., 1., 0., 0., 0., 0., 0., 1., 0.]], device='cuda:0')
prefix log/PeMS/
checkpoint_temp_path log/PeMS//temp.pth
checkpoint_best_path log/PeMS//best.pth
tensorboard_path log/PeMS/
record_path log/PeMS/record.txt
eps 0.1
parse <bound method DefaultConfig.parse of <config.DefaultConfig object at 0x14a34d855ee0>>
output <bound method DefaultConfig.output of <config.DefaultConfig object at 0x14a34d855ee0>>
Original hour values:
0      0
1      1
2      2
3      3
4      4
5      5
6      6
7      7
8      8
9      9
10    10
11    11
12    12
13    13
14    14
15    15
16    16
17    17
18    18
19    19
Name: hour, dtype: int64
df_stamp columns after adding minute: Index(['date', 'month', 'day', 'weekday', 'hour', 'minute'], dtype='object')
df_stamp columns before drop: Index(['date', 'month', 'day', 'weekday', 'hour', 'minute'], dtype='object')
Before normalization:
   month  day  weekday  hour  minute
0      1    1        3     0       0
1      1    1        3     1       0
2      1    1        3     2       0
3      1    1        3     3       0
4      1    1        3     4       0
After normalization:
data_stamp shape: (58285, 5)
data_stamp example:
 [[1 1 3 0 0]
 [1 1 3 1 0]
 [1 1 3 2 0]
 [1 1 3 3 0]
 [1 1 3 4 0]]
Dataset split: 0, border1: 0, border2: 58285
data_x shape: (58285, 10), data_y shape: (58285, 10), data_stamp shape: (58285, 5)
data_stamp shape: (58285, 5)
data_stamp example:
 [[1 1 3 0 0]
 [1 1 3 1 0]
 [1 1 3 2 0]
 [1 1 3 3 0]
 [1 1 3 4 0]]
df_stamp columns: Index(['date', 'month', 'day', 'weekday', 'hour', 'minute'], dtype='object')
df_stamp head:
                  date  month  day  weekday  hour  minute
0 2015-01-01 00:00:00      1    1        3     0       0
1 2015-01-01 01:00:00      1    1        3     1       0
2 2015-01-01 02:00:00      1    1        3     2       0
3 2015-01-01 03:00:00      1    1        3     3       0
4 2015-01-01 04:00:00      1    1        3     4       0
Dataset fields:
Batch fields:
Field 0: torch.Size([50, 12, 10])
Field 1: torch.Size([50, 22, 10])
Field 2: torch.Size([50, 12, 5])
Field 3: torch.Size([50, 22, 5])
